{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9gXzxFioRA9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673692000964,"user_tz":-480,"elapsed":6410,"user":{"displayName":"Janin Manalili","userId":"03008455629451036416"}},"outputId":"dc4001fa-168f-4135-d0f1-021cad82bf5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 1319270831416312176\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 14415560704\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 17042471542350177192\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":1}],"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"]},{"cell_type":"code","source":["!nvcc --version\n","!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc_plugin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RWs0moIJdQd","executionInfo":{"status":"ok","timestamp":1673692008641,"user_tz":-480,"elapsed":7681,"user":{"displayName":"Janin Manalili","userId":"03008455629451036416"}},"outputId":"5989176a-ccd1-4fc0-9a55-748dd84f4540"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-po4khzpu\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-po4khzpu\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4304 sha256=c407c05f0110aeb4fe86ea37be1e9039c73c8cfc0b0c0992283b4d72885e8ae3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-od_byhsh/wheels/f3/08/cc/e2b5b0e1c92df07dbb50a6f024a68ce090f5e7b2316b41756d\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"]}]},{"cell_type":"code","source":[" ! df -h"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4Ocz6Dsal4e","executionInfo":{"status":"ok","timestamp":1673692008643,"user_tz":-480,"elapsed":11,"user":{"displayName":"Janin Manalili","userId":"03008455629451036416"}},"outputId":"f317da9a-936f-4ab7-dfd4-94e96780a57c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Filesystem      Size  Used Avail Use% Mounted on\n","overlay          79G   23G   56G  30% /\n","tmpfs            64M     0   64M   0% /dev\n","shm             5.7G     0  5.7G   0% /dev/shm\n","/dev/root       2.0G  1.1G  841M  58% /sbin/docker-init\n","tmpfs           6.4G   40K  6.4G   1% /var/colab\n","/dev/sda1        80G   49G   32G  61% /opt/bin/.nvidia\n","tmpfs           6.4G     0  6.4G   0% /proc/acpi\n","tmpfs           6.4G     0  6.4G   0% /proc/scsi\n","tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"]}]},{"cell_type":"code","source":[" !cat /proc/cpuinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6EKhRmzqapmg","executionInfo":{"status":"ok","timestamp":1673692009389,"user_tz":-480,"elapsed":753,"user":{"displayName":"Janin Manalili","userId":"03008455629451036416"}},"outputId":"328345d1-ceaf-4079-970d-4f79822cc21b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2199.998\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n","bogomips\t: 4399.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2199.998\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n","bogomips\t: 4399.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"]}]},{"cell_type":"markdown","source":["# Kernel Code"],"metadata":{"id":"_44Vp3XBR_yI"}},{"cell_type":"code","source":["%%cu\n","\n","#include <cstdio>\n","#include <iostream>\n","#include \"cuda_runtime.h\"\n","#include \"device_launch_parameters.h\"\n","#include \"cuda_runtime_api.h\"\n","#include <stdio.h>\n","#include <cuda.h>\n","#include <stdlib.h>\n","#include <math.h>\n","#include <time.h>\n","\n","using namespace std;\n","\n","#define BLOCK_DIM 16\n","\n","void initMat(float *matrix, int size) {\n","    for (int i = 0; i < size*size; i++) {\n","        matrix[i] = 0;\n","    }\n","}\n","\n","void randMat(float *matrix, int size) {\n","    srand((unsigned int)time(NULL));\n","    for (int i = 0; i < size; ++i) {\n","        for (int j = 0; j < size; ++j) {\n","            matrix[i * size + j] = ((float)rand() / (float)(RAND_MAX)) * 100;\n","        }\n","    }    \n","}\n","\n","void printMat(float *matrix, int size) {\n","    for (int i = 0; i < size; ++i) {\n","        for (int j = 0; j < size; ++j)\n","            printf(\"%.2f  \", matrix[i * size + j]);\n","        printf(\"\\n\");\n","    }    \n","}\n","\n","\n","__global__ void luFactorizationDev(float* matrix, float* upper, float* lower, int size) {\n","\n","\tfor (size_t k = 0; k < BLOCK_DIM; ++k)\n","\t{\n","\t\tunsigned int x = threadIdx.x;\n","\t\tunsigned int y = threadIdx.y;\n","\t\t\n","\t\tif(x >= k && x < size && y == k)\n","\t\t{\t\n","\t\t\tint sum = 0.;\n","\t\t\tfor (size_t p = 0; p < k; ++p)\n","\t\t\t{\n","\t\t\t\tsum += lower[p + k * size] * upper[x + p * size];\n","\t\t\t}\n","\t\t\tupper[x + k * size] = matrix[x + k * size] - sum;\t\n","\t\t}\n","\t\t__syncthreads();\n","\n","\t\tif(y >= k && y < size && x == k)\n","\t\t{\n","\t\t\tint sum = 0.;\n","\t\t\tfor (size_t p = 0; p < k; ++p)\n","\t\t\t{\n","\t\t\t\tsum += lower[p + y * size] * upper[k + p * size];\n","\t\t\t}\n","\t\t\tlower[k + y * size] = (matrix[k + y * size] - sum) / upper[k + k * size];\n","\t\t}\n","\t\t__syncthreads();\n","\t}\n","}\n","\n","void luFactorizationHost(float *matrix, float *upper, float *lower, int size) {\n","\tfor (int i = 0; i < size; i++) {\n","\t\t// Upper triangular\n","\t\tfor (int k = i; k < size; k++) {\n","\t\t\tint sum = 0;\n","\t\t\tfor (int j = 0; j < i; j++)\n","\t\t\t\tsum += (lower[i * size + j] * upper[j * size + k]);\n","\t\t\tupper[i * size + k] = matrix[i * size + k] - sum;\n","\t\t}\n","\n","\t\t// Lower triangular\n","\t\tfor (int k = i; k < size; k++) {\n","\t\t\tif (i == k)\n","\t\t\t\tlower[i * size + i] = 1;\n","\t\t\telse {\n","\t\t\t\tint sum = 0;\n","\t\t\t\tfor (int j = 0; j < i; j++)\n","\t\t\t\t\tsum += (lower[k * size + j] * upper[j * size + i]);\n","\t\t\t\tlower[k * size + i] = (matrix[k * size + i] - sum) / upper[i * size + i];\n","\t\t\t}\n","\t\t}\n","\t}\n","}\n","\n","\n","int main()\n","{\n","    float* dev_A, *dev_up, *dev_low;\n","    float* A, *up, *low;\n","    int N = 1023;\n","    int size = N * N * sizeof(float);\n","    dim3 threadsPerBlock(BLOCK_DIM, BLOCK_DIM);\n","    dim3 numBlocks(ceil((float)N / threadsPerBlock.x), ceil((float)N / threadsPerBlock.y));\n","   \n","    cudaMallocHost((void**)&A, size);\n","    cudaMallocHost((void**)&up, size);\n","    cudaMallocHost((void**)&low, size);\n","         \n","    cudaMalloc((void**)&dev_A, size);\n","    cudaMalloc((void**)&dev_up, size);\n","    cudaMalloc((void**)&dev_low, size);\n","\n","    randMat(A, N);\n","    initMat(up, N);\n","    initMat(low, N);\n"," \n","    //printf(\"Matrix A\\n\");\n","\n","    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(dev_up, up, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(dev_low, low, size, cudaMemcpyHostToDevice);\n"," \n","    cudaEvent_t start, stop;\n","    float add_et = 0.0;\n","    float add_bw = 0.0;\n","    float msec = 0.0;\n","    for (int i = 0; i < 10; i++) {\n","      cudaEventCreate(&start);\n","      cudaEventCreate(&stop);\n","      cudaEventRecord(start);\n","      \n","      luFactorizationDev << <numBlocks, threadsPerBlock >> > (dev_A, dev_up, dev_low, N);\n","      \n","      cudaEventRecord(stop);\n","      cudaEventSynchronize(stop);\n","      cudaEventElapsedTime(&msec, start, stop);\n","      add_et += msec;\n","      add_bw += N*N * 4 * 3 / msec/ 1e6;\n","      cudaEventDestroy(start);\n","      cudaEventDestroy(stop);\n","    }\n"," \n","    clock_t begin = clock();\n","    cudaMemcpy(up, dev_up, sizeof(float)*N*N, cudaMemcpyDeviceToHost);\n","    cudaMemcpy(low, dev_low, sizeof(float)*N*N, cudaMemcpyDeviceToHost);\n","    clock_t end = clock();\n","    add_et += (float)(end - begin) / CLOCKS_PER_SEC;\n"," \n","    add_et = add_et / 10;\n","    add_bw = add_bw / 10;\n","    printf(\"Kernel Average Elapsed Time: %.6fs\\n\", add_et/1000);\n","    printf(\"Kernel Average Effective Bandwidth: %fgb/s\\n\", add_bw);\n","\n"," \n","    printf(\"\\nKernel\\n\");\n","    printf(\"Lower matrix\\n\");\n","    //printMat(low, N);\n"," \n","    printf(\"\\n\");\n","    printf(\"Upper matrix\\n\");\n","    //printMat(up, N);\n"," \n","    \n","    add_et = 0;\n","    for (int i = 0; i < 10; i++) {\n","      clock_t begin = clock();\n","      luFactorizationHost(A, up, low, N);\n","      clock_t end = clock();\n","      add_et += (float)(end - begin) / CLOCKS_PER_SEC;\n","    }\n","    \n","    add_et = add_et / 10;\n"," \n","    printf(\"Host Average Elapsed Time: %.6fs\\n\", add_et); \n"," \n","    \n","    printf(\"\\nHost\\n\");\n","    printf(\"Lower matrix\\n\");\n","    //printMat(low, N);\n","\n","    printf(\"\\n\");\n","    printf(\"Upper matrix\\n\");\n","    //printMat(up, N);\n"," \n","    return 0;\n","\n","}"],"metadata":{"id":"Rout90nzRKCk"},"execution_count":null,"outputs":[]}]}